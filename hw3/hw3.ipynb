{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["\\begin{center}\n", "\\begin{huge}\n", "DATA203 Foundational Python (Prof. Maull) / Fall 2025 / HW3\n", "\\end{huge}\n", "\\end{center}\n", "\n", "| Points <br/>Possible | Due Date | Time Commitment <br/>(estimated) |\n", "|:---------------:|:--------:|:---------------:|\n", "| 25 | Thursday, November  13 @ midnight | _up to_ 15 hours |\n", "\n", "\n", "* **GRADING:** Grading will be aligned with the completeness of the objectives.\n", "\n", "* **INDEPENDENT WORK:** Copying, cheating, plagiarism  and academic dishonesty _are not tolerated_ by University or course policy.  Please see the syllabus for the full departmental and University statement on the academic code of honor.\n", "\n", "## OBJECTIVES\n", "* Explore a digital humanities dataset in Python and Pandas.\n", "\n", "* Develop statistical summaries of the data.\n", "\n", "* Build a Seaborn heatmap for the monthly publication counts for all years.\n", "\n", "## WHAT TO TURN IN\n", "You will enjoy the highest benefits of the starter notebook\n", "if you clone the HW Github repository from your Jupyter Hub\n", "terminal with the command:\n", "\n", "```bash\n", "  git clone https://github.com/kmhuads/f25_data203.git\n", "``` \n", "\n", "This will ensure you have the most updated files and starter \n", "notebook.\n", "\n", "Once you have cloned the repository, you can edit the\n", "starter notebook with your solution code.\n", "\n", "When you are done with your work, it will be best to zip\n", "your `hw2` folder and all sub-folders with the terminal command\n", "(one level outside your notebook folder):\n", "\n", "``` bash\n", "  zip -r data203_hw3_maull.zip ./hw3\n", " ```\n", "\n", "This will produce the file with all necessary supporting files\n", "(notebooks, data output, etc.) \n", "then\n", "download it from the Jupyter Hub to your local machine, \n", "then upload the `.zip` to Teams.\n", "\n", "If are confused on how to do this, please ask, \n", "or visit one of the many tutorials\n", "on the basics of using zip in Linux.  \n", "\n", "If you choose not to use the provided notebook, you will still need to turn in a\n", "`.ipynb` Jupyter Notebook and corresponding files according to the instructions in\n", "this homework.\n", "\n", "\n", "## ASSIGNMENT TASKS\n", "### (30%) Explore a digital humanities dataset in Python and Pandas. \n", "\n", "\n", "As a data scientist, we must remain curious.\n", "\n", "In lecture, we learned about the importance\n", "of expertise and the relationships between\n", "math/statistics and coding/\"hacking\" (see\n", "the Data Science venn diagram in slides).\n", "\n", "Working with any dataset, large or small, \n", "and becoming curious about the contents and\n", "questions that can be asked about _any_ data\n", "is a skill that will cultivate as it \n", "serves your future growth.\n", "\n", "We are going to do just that in this assignment.\n", "\n", "It is always suprising to learn about the \n", "variety of data that is openly available online.\n", "\n", "One such dataset is a curated digital anthology\n", "of African American Poetry.  _African American Poetry: A Digital Anthology (1870-1928)_ \n", "is such a dataset.  Curated by Dr. Amardeep Singh, an \n", "English scholar at Lehigh\n", "University, it contains an open-access dataset of \n", "poetry that is now out of copyright -- at a time\n", "when the _digital_ tools available to explore it \n", "are beyond imaginable just 50 years ago.\n", "\n", "The interactive website for this data is here:\n", "\n", "* **website** &#8594; [African American Poetry: A Digital Anthology](https://scalar.lehigh.edu/african-american-poetry-a-digital-anthology/welcome-african-american-poetry--a-digital-anthology?path=index) by Amardeep Singh\n", "\n", "Full citation: \n", "\n", "> Amardeep Singh, Ed. African American Poetry: \n", "  A Digital Anthology. Lehigh University, 2024. \n", "  [https://scalar.lehigh.edu/african-american-poetry-a-digital-anthology/index](https://scalar.lehigh.edu/african-american-poetry-a-digital-anthology/index). \n", "\n", "The site includes  interesting information\n", "about the project rationale, the contents of the\n", "data and even some research analyses that might \n", "be performed.\n", "\n", "**&#167; Task:**  **1.1 Learn about the African American Poetry: A Digital Anthology website and research project.**\n", "\n", "1. Browse the site and summarize the contents in your own words.  please\n", "   keep your summary to under 250 words (in other words, _be brief_ about\n", "   what you learned while browsing).\n", "\n", "2. In late 1944 Dorothy Porter, a librarian from Howard University, \n", "   extended and revised a 1916 compilation of books of \n", "   poetry by African American authors. Her preface and checklist\n", "   titled _North American Negro Poets: A Bibliographical Checklist 1760-1944_\n", "   can be seen here:\n", "\n", "   * [Dorothy Porter, \"North American Negro Poets: A Bibliographical Checklist of Their Writings, 1760-1944\" (1945)](https://scalar.lehigh.edu/african-american-poetry-a-digital-anthology/dorothy-porter-north-american-negro-poets-a-bibliographical-checklist-of-their-writings-1760-194)\n", "\n", "   Read the preface written by Ms. Porter and respond to her statement:\n", "\n", "   > It must be mentioned that one of the principal objectives of this bibliography is to afford an index to the relative distribution of books and other published materials of Negro poetry among our libraries and thus indirectly to reflect the richness of American holdings in this sphere. \n", "\n", "   by answering the question: \n", "   \n", "   > _Consider the tools available to us in 2025.  How does this new Digital Anthology  help accomplish the original goals set forth in 1944?_ \n", "\n", "3. Explore the research questions presented by the Anthology here (in the number section 2, \n", "   there is a bulleted list of questions):\n", "\n", "   * Dr. Amardeep's preliminary [research questions.](https://scalar.lehigh.edu/african-american-poetry-a-digital-anthology/exploring-datasets-related-to-african-american-poetry)\n", "\n", "   Answer the question:\n", "   \n", "   > _Which of these research questions interests you and why?_\n", "\n", "\n", "**&#167; Task:**  **1.2 Load and explore the primary dataset from the Digital Anthology.**\n", "\n", "You will find the primary dataset for the Anthology here:\n", "\n", "* [African American Periodical Poetry (1900-1928)](https://scalar.lehigh.edu/african-american-poetry-a-digital-anthology/external?link=https%3A%2F%2Fmelaniewalsh.github.io%2Fresponsible-datasets-in-context%2Fposts%2Fafrican-american-periodical-poetry%2Faa-periodical-poetry.html&prev=https%3A%2F%2Fscalar.lehigh.edu%2Fafrican-american-poetry-a-digital-anthology%2Fexploring-datasets-related-to-african-american-poetry) at Responsible Datasets\n", "\n", "Use Pandas to perform the following in your Jupyter notebook:\n", "\n", "1. Load the dataset from the raw data URL on the page using only `pandas.read_csv()`.\n", "2. Give the number of rows and columns in the dataset.\n", "3. Learn how to use [`DataFrame.value_counts()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.value_counts.html) \n", "   and report the counts of the number of works from 1900-1928.\n", "4. Use `value_counts()` to report the number of `Magazine Type` publications which \n", "   were `Predom. Black`. \n", "5. Provide the percent of total `Magazine Type` which are `Predom. Black` (you'll need to \n", "   sum all `Magazine Type` and use that to find the ratio or percent).\n", "\n", "\n", "\n", "### (50%) Develop statistical summaries of the data. \n", "\n", "\n", "We will extend the work we started in the first part and continue \n", "to explore the data.\n", "\n", "**&#167; Task:**  **2.1 Provide a table which shows the percent of publications by year.**\n", "\n", "* You will need to get all the counts of publications by year (use the `year` column)\n", "   and divide all counts by the total number of publications.\n", "\n", "\n", "**&#167; Task:**  **2.2 Use the provided function `get_monthly_pub_counts()` to create the Series for 1904, 1905 and 1906.**\n", "\n", " * You can just run `get_monthly_pub_counts()` on the three years in separate cells.\n", "\n", "\n", "**&#167; Task:**  **2.3 Continue using `get_monthly_pub_counts()` to produce a new DataFrame with counts\n", "for ALL years, 1900-1928.**\n", "\n", "The new DataFrame will have the year as the index and the ordered months as the \n", "columns.  Each value in the DataFrame will include the counts for that year and month. \n", "\n", "Your final DataFrame will look something like:\n", "\n", "|      |   January |   February |  ...  |     November |   December |\n", "|-----:|----------:|-----------:|------:|-------------:|-----------:|\n", "| 1900 |         0 |          0 |   ... |            1 |          2 |\n", "| ...  | ...  | ...  | ...  | ...  | ...  |\n", "| 1929 |         2 |          5 |   ... |            3 |          9 |\n", "\n", "\n", "\n", "### (20%) Build a Seaborn heatmap for the monthly publication counts for all years. \n", "\n", "We learned in lecture that \n", "visualizing data makes everything\n", "better -- most of us and our peers\n", "do not want to see thousands of \n", "data points in a table, they want\n", "to have a picture of that data.\n", "\n", "We are going to use a library\n", "called [Seaborn]() to make a \n", "heatmap of the data table you\n", "produced in the previous section.\n", "\n", "**&#167; Task:**  **3.1 Build a heatmap of all the publication counts from 1900-1928.**\n", "\n", "Study the documentation for Seaborn heat maps here:\n", "\n", "* [`seaborn.heatmap`](https://seaborn.pydata.org/generated/seaborn.heatmap.html)\n", "\n", "Don't over think this, you will not need to do much work\n", "to make the heatmap.  If you have more than 2 lines\n", "of code, you are on the wrong track.  You can do it in 1 \n", "line of code once you have the complete DataFrame \n", "from the previous part.\n", "\n", "\n", "**&#167; Task:**  **3.2 Please look at the heatmap and make 3 observations\n", "about what you see.**\n", "\n", "You may include observations about the \n", "months and years which are most frequent, trends, data gaps, etc.\n", "\n", "\n", "\n"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python [default]", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.1"}, "toc": {"colors": {"hover_highlight": "#DAA520", "navigate_num": "#000000", "navigate_text": "#333333", "running_highlight": "#FF0000", "selected_highlight": "#FFD700", "sidebar_border": "#EEEEEE", "wrapper_background": "#FFFFFF"}, "moveMenuLeft": true, "nav_menu": {"height": "12px", "width": "252px"}, "navigate_menu": true, "number_sections": false, "sideBar": true, "threshold": "1", "toc_cell": false, "toc_section_display": "block", "toc_window_display": true, "widenNotebook": false}}, "nbformat": 4, "nbformat_minor": 0}